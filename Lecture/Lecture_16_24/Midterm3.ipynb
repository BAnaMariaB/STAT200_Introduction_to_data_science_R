{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "012825f9",
   "metadata": {},
   "source": [
    "# L16 : String Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cd4a28",
   "metadata": {},
   "source": [
    "**What is string processing?**\n",
    " *  String processing is the process where we can process or manipulate strings to extract useful information for our analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9040287d",
   "metadata": {},
   "source": [
    "**Index for the Basic string processing**\n",
    "  * `strsplit(x, split)`\n",
    "    * splits a string `x` by another string `split`\n",
    "    * Splits a string into substrings based on a specified delimiter (split).\n",
    "    * Inputs : \n",
    "        * x is the input string or character vector.\n",
    "        * split is the pattern (string or character) on which to divide the input.\n",
    "    * Returns an unstrutured list of strings of the split string (ex\"Ana are mere\" -> \"Ana\" \"are\" \"mere\")\n",
    "    * Typical Syntax : \n",
    "        * strsplit(x = \"Your text here\", split = \" \")\n",
    "\n",
    "  * `paste0(x1, x2, x3, ...)`\n",
    "    * concatenates strings with no delimiter or separation between the strings.\n",
    "\n",
    "  * `paste(x1, x2, x3, ..., sep, collapse)`\n",
    "    * concatenates strings with a string `sep` in between. Can also be used to concatenate strings in a vector using `collapse`\n",
    "\n",
    "  * `toupper(x)`\n",
    "    * converts all characters in a string to upper case\n",
    "\n",
    "  * `tolower(x)`\n",
    "    * converts all characters in a string to lower case\n",
    "\n",
    "  * `nchar(x)`\n",
    "    * outputs the number of characters in a string\n",
    "    \n",
    "  * `substring(text, first, last)`\n",
    "    * Extracts the `first` though `last` characters from a string `text`\n",
    "\n",
    "  * `grepl(pattern, x)`\n",
    "    * Outputs a logical representing if a `pattern` is in a string `x`\n",
    "    \n",
    "  * `grep(pattern, x)`\n",
    "    * Outputs which elements in a character vector `x` contains a `pattern`\n",
    "\n",
    "  * `gsub(pattern, replacement, x)`\n",
    "    * Replaces a `pattern` in string `x` with another string `replacement`\n",
    "\n",
    "  * `gregexpr(pattern, text)`\n",
    "    * Outputs the location of the first character of a `pattern` in a string `text`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef457768",
   "metadata": {},
   "source": [
    "# L17 : Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf58966",
   "metadata": {},
   "source": [
    "\n",
    "## üîç Basic R String Matching Functions\n",
    "\n",
    "### 1. `grepl(pattern, x)`\n",
    "- **Purpose**: Checks if the `pattern` exists in each element of character vector `x`.\n",
    "- **Returns**: A logical vector (`TRUE` or `FALSE` per element).\n",
    "- **Example**:\n",
    "  ```r\n",
    "  grepl(\"data\", c(\"data science\", \"statistics\"))\n",
    "  # [1] TRUE FALSE\n",
    "  ```\n",
    "\n",
    "### 2. `grep(pattern, x, value = FALSE)`\n",
    "- **Purpose**: Returns the **indices** of elements that match the `pattern`.\n",
    "- **Set `value = TRUE`** to return the matching strings instead.\n",
    "- **Example**:\n",
    "  ```r\n",
    "  grep(\"science\", c(\"data science\", \"biology\"))\n",
    "  # [1] 1\n",
    "\n",
    "  grep(\"science\", c(\"data science\", \"biology\"), value = TRUE)\n",
    "  # [1] \"data science\"\n",
    "  ```\n",
    "\n",
    "### 3. `gsub(pattern, replacement, x)`\n",
    "- **Purpose**: Replaces all matches of `pattern` in `x` with `replacement`.\n",
    "- **Example**:\n",
    "  ```r\n",
    "  gsub(\"dog\", \"cat\", \"The dog runs fast\")\n",
    "  # [1] \"The cat runs fast\"\n",
    "  ```\n",
    "\n",
    "### 4. `gregexpr(pattern, text)`\n",
    "- **Purpose**: Returns a list of the **starting positions** of all matches of `pattern` in `text`.\n",
    "- **Example**:\n",
    "  ```r\n",
    "  gregexpr(\"\\d\", \"abc123\")\n",
    "  # [[1]] 4 5 6\n",
    "  ```\n",
    "\n",
    "`rematches()` : function that extracts a pattern from a string\n",
    "---\n",
    "\n",
    "## üî£ Regular Expression Patterns (Regex Syntax)\n",
    "\n",
    "### 1. Character Classes\n",
    "| Pattern     | Meaning                              |\n",
    "|-------------|---------------------------------------|\n",
    "| `.`         | Any single character except newline    |\n",
    "| `[abc]`     | Matches one of: a, b, or c            |\n",
    "| `[^abc]`    | Matches anything except a, b, or c    |\n",
    "| `[a-z]`     | Matches any lowercase letter          |\n",
    "| `[0-9]` or `\\d` | Matches any digit                |\n",
    "| `\\D`        | Non-digit character                  |\n",
    "| `\\s`        | Whitespace character                 |\n",
    "| `\\S`        | Non-whitespace character             |\n",
    "| `\\w`        | Word character (letter, digit, `_`)  |\n",
    "| `\\W`        | Non-word character                   |\n",
    "\n",
    "### 2. Anchors\n",
    "| Pattern | Meaning                      |\n",
    "|---------|-------------------------------|\n",
    "| `^`     | Start of string               |\n",
    "| `$`     | End of string                 |\n",
    "\n",
    "### 3. Quantifiers\n",
    "| Pattern   | Meaning                          |\n",
    "|-----------|-----------------------------------|\n",
    "| `*`       | 0 or more occurrences              |\n",
    "| `+`       | 1 or more occurrences              |\n",
    "| `?`       | 0 or 1 occurrence                  |\n",
    "| `{n}`     | Exactly n occurrences              |\n",
    "| `{n,}`    | At least n occurrences             |\n",
    "| `{n,m}`   | Between n and m occurrences        |\n",
    "| `t*m`     | zero or more of the letter t       |\n",
    "\n",
    "### 4. Grouping and Alternation\n",
    "| Pattern     | Meaning                              |\n",
    "|-------------|---------------------------------------|\n",
    "| `(abc)`     | Grouping (for precedence/capture)     |\n",
    "| `a pipe b`       | Either a or b                         |\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Practical Examples\n",
    "\n",
    "### Match a word anywhere in a sentence\n",
    "```r\n",
    "pattern <- \"science\"\n",
    "text <- c(\"data science\", \"political science\", \"biology\")\n",
    "grep(pattern, text, value = TRUE)\n",
    "```\n",
    "\n",
    "### Replace multiple spaces with a single space\n",
    "```r\n",
    "gsub(\" +\", \" \", \"this    is  messy\")\n",
    "```\n",
    "\n",
    "### Extract numeric values from a string\n",
    "```r\n",
    "text <- \"Height: 5'10\\\"\"\n",
    "gregexpr(\"\\d+\", text)\n",
    "# Returns positions of numbers\n",
    "```\n",
    "\n",
    "### Match U.S. phone number format\n",
    "```r\n",
    "pattern <- \"\\(\\d{3}\\) \\d{3}-\\d{4}\"\n",
    "text <- \"Call (123) 456-7890 now!\"\n",
    "grepl(pattern, text)\n",
    "```\n",
    "\n",
    "## üß† Tips\n",
    "- Always use double backslashes (`\\\\`) in R regex to escape characters.\n",
    "- Combine functions: use `strsplit()` + regex to tokenize or clean text.\n",
    "- Wrap your regex in `^...$` to match the entire string.\n",
    "- Test patterns using `grepl()` before replacing or extracting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aade91",
   "metadata": {},
   "source": [
    "# L18  Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233d3e26",
   "metadata": {},
   "source": [
    "# R Web Scraping - Cheatsheet (Advanced Edition)\n",
    "\n",
    "## üìò What is Web Scraping?\n",
    "Web scraping is the **automated extraction of data from websites**, especially when data is not available in structured file formats like `.csv`, `.json`, or `.xlsx`. Instead, the data lives inside HTML code ‚Äî and we use R to **load, navigate, and extract** this information.\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Primary Package: `rvest`\n",
    "- Built for scraping and parsing HTML in a tidy way.\n",
    "- Uses CSS selectors to locate elements.\n",
    "\n",
    "---\n",
    "\n",
    "## üåê How the Web Works (Minimal Background)\n",
    "- Websites are built in **HTML (HyperText Markup Language)**.\n",
    "- HTML is hierarchical: tags nest within tags (e.g., `<body>`, `<div>`, `<h2>`).\n",
    "- Browsers render this structure into the visuals we see.\n",
    "- We can **view the source code** (Right-click ‚Üí View Page Source or `F12` ‚Üí Inspect) to understand how data is embedded.\n",
    "\n",
    "---\n",
    "\n",
    "## üß© HTML Vocabulary You Must Know\n",
    "| Concept         | Meaning                                                                 |\n",
    "|----------------|-------------------------------------------------------------------------|\n",
    "| **Tag**        | HTML instruction, e.g., `<p>`, `<h2>`                                   |\n",
    "| **Element**    | A tag plus its content: `<p>Hello</p>`                                  |\n",
    "| **Text**       | The content displayed between opening & closing tags                    |\n",
    "| **Attribute**  | Modifier inside opening tag: `<a href=\"url\">`                         |\n",
    "| **Attribute Value** | The value assigned to the attribute: `href=\"https://...\"`         |\n",
    "| **Class**      | A common attribute: used to group/style elements                        |\n",
    "\n",
    "---\n",
    "\n",
    "## üîÅ Full Web Scraping Workflow\n",
    "\n",
    "### 1. Load the Web Page\n",
    "```r\n",
    "library(rvest)\n",
    "html <- read_html(\"https://example.com\")\n",
    "```\n",
    "\n",
    "### 2. Navigate and Explore with DevTools\n",
    "Use **Right-click ‚Üí Inspect** to:\n",
    "- Find tag names (e.g., `h2`, `table`, `p`)\n",
    "- Identify class names (e.g., `.director`)\n",
    "- Check attributes (e.g., `href`, `data-id`)\n",
    "\n",
    "### 3. Extract Elements\n",
    "```r\n",
    "html_elements(html, \"section\")               # Extract <section> blocks\n",
    "html_elements(html, \"section h2\")            # Nested selection: <h2> inside <section>\n",
    "html_elements(html, \".director\")            # All elements with class=\"director\"\n",
    "```\n",
    "\n",
    "### 4. Extract Visible Text\n",
    "```r\n",
    "html_text(elements, trim = TRUE)             # Only the human-visible part of an element\n",
    "```\n",
    "\n",
    "### 5. Extract Attributes\n",
    "```r\n",
    "html_attr(elements, \"href\")                  # Get hyperlink references\n",
    "html_attr(elements, \"data-id\")               # Grab custom attribute values\n",
    "```\n",
    "\n",
    "```r\n",
    "html_elements(html,\"title\")                  # extract all elements with <title> tag\n",
    "html_table()                                 # extracts all tabular data with a <table>\n",
    "                                             # tag and outputs an unstructured list of df\n",
    "```\n",
    "\n",
    "```r\n",
    "<title>Ana are mere</title>\n",
    "html_text(title_element)                    # extract the string \"Ana are mere\"\n",
    "```\n",
    "\n",
    "```r\n",
    "<meta name=\"viewport\" content=\"\">\n",
    "html_attr(meta_element,\"name\")                    # extract the string \"Ana are mere\"\n",
    "```\n",
    "\n",
    "```r\n",
    "html_elements(html,\".highlight\")                    # extract all elements with class = \"highlight\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Table Extraction Workflow\n",
    "\n",
    "### Step-by-step:\n",
    "```r\n",
    "tables <- html_elements(html, \"table\")       # All <table> elements\n",
    "all_tables <- html_table(tables)             # Convert to list of data frames\n",
    "films <- all_tables[[2]]                     # Choose relevant table\n",
    "```\n",
    "\n",
    "### Cleaning Extracted Table\n",
    "```r\n",
    "names(films) <- c(\"title\", \"director\", \"release_date\", ...)  # Rename cols\n",
    "films <- films[, 1:(ncol(films) - 1)]                         # Drop reference col\n",
    "```\n",
    "\n",
    "### Extract and Clean Release Dates\n",
    "```r\n",
    "pattern <- \"\\\\d{4}-\\\\d{2}-\\\\d{2}\"\n",
    "locs <- gregexpr(pattern, films$release_date)\n",
    "films$release_date <- sapply(regmatches(films$release_date, locs), `[`, 1)\n",
    "```\n",
    "\n",
    "### Remove Non-Movie Rows (e.g., Trilogy Headers)\n",
    "```r\n",
    "films <- films[!grepl(\"trilogy\", films$title, ignore.case = TRUE), ]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Practical Summary: Key Functions\n",
    "| Function               | Use Case                                      |\n",
    "|------------------------|-----------------------------------------------|\n",
    "| `read_html()`          | Load the HTML content from a URL              |\n",
    "| `html_elements()`      | Find all matching HTML tags or classes        |\n",
    "| `html_text()`          | Extract readable content                      |\n",
    "| `html_attr()`          | Pull out values of specific attributes        |\n",
    "| `html_table()`         | Convert HTML `<table>` into a data frame      |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Static vs. Dynamic Websites\n",
    "| Type     | Description                                                  | Tools       |\n",
    "|----------|--------------------------------------------------------------|-------------|\n",
    "| **Static**   | Content is part of the original HTML (scrape with `rvest`)  | `rvest`     |\n",
    "| **Dynamic**  | Content appears only after interaction/JS execution        | `RSelenium` |\n",
    "\n",
    "> üîç Dynamic scraping requires automation: loading pages, clicking buttons, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Final Reminders\n",
    "- Always inspect HTML structure before scraping.\n",
    "- Tag navigation is hierarchical ‚Äî use nested selectors for deeper elements.\n",
    "- Use classes (with `.`) or tag names to isolate what you need.\n",
    "- Attributes often contain useful metadata like IDs or links.\n",
    "- Cleaning your data (renaming, trimming, regex) is a normal part of scraping.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7aad44",
   "metadata": {},
   "source": [
    "# L20 +L21 : Data Vizualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee5aafc",
   "metadata": {},
   "source": [
    "\n",
    "## üîç What is Data Visualization?\n",
    "Data visualization is the practice of representing data through graphical formats. It helps uncover trends, patterns, outliers, and relationships within a dataset and supports communication of insights.\n",
    "\n",
    "In R, **ggplot2** is the dominant package for creating clear, structured, and customizable data graphics based on the **Grammar of Graphics** approach.\n",
    "\n",
    "* `ggplot()` :  creates an empty plot is created\n",
    "* `library(ggplot2)` : loads necessary creates a ggplot\n",
    "\n",
    "* for which type of data is the size visual dimension appropriate for your plot :  ordinal (categorical) and numeric\n",
    "* for which type of data is the color visual dimension appropriate for your plot : ordinal(categorical), numeric and nominal(categorical)\n",
    "* A barplot is a better substitue for a pie chart\n",
    "* A log transformation is appropriate when your data are severky right skewed\n",
    "* the default colors in ggplot aren't colorblind friendly\n",
    "* facet_wrap() you can include another variable in a box plot using the fill= argument\n",
    "* Barplots need to include zerro\n",
    "* 3D plotting is good when\n",
    "---\n",
    "\n",
    "## üß† Grammar of Graphics: Conceptual Structure\n",
    "The philosophy of ggplot2 is to build a plot layer-by-layer using consistent rules.\n",
    "\n",
    "### üß± Core Components\n",
    "Each plot consists of the following elements:\n",
    "\n",
    "1. **Data**: The dataset you are working with\n",
    "2. **Aesthetics (`aes`)**: Mappings from variables to visual properties\n",
    "3. **Geoms**: Geometric objects that define how data should appear (bars, points, lines)\n",
    "4. **Scales**: Define axes and color ranges\n",
    "5. **Facets**: Split data into subplots\n",
    "6. **Coordinate System**: Defines the plotting space\n",
    "7. **Theme**: Controls the visual appearance\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è ggplot2 Plot Syntax\n",
    "```r\n",
    "ggplot(data = <DATA>) +\n",
    "  aes(x = <X-VAR>, y = <Y-VAR>, ...) +\n",
    "  geom_<GEOM>() +\n",
    "  other_layers\n",
    "```\n",
    "Each component is added with `+`, allowing flexible customization.\n",
    "\n",
    "---\n",
    "\n",
    "## üé® Aesthetic Mappings (`aes()`)\n",
    "### üîß What is an Aesthetic?\n",
    "An **aesthetic** is a visual property such as position, color, or size that gets mapped to a data variable.\n",
    "\n",
    "| Aesthetic     | Purpose                                | Notes                                      |\n",
    "|---------------|----------------------------------------|--------------------------------------------|\n",
    "| `x`, `y`      | Axes values                            | Most basic aesthetics                      |\n",
    "| `color`       | Outline color for lines/points         | Use for categories                         |\n",
    "| `fill`        | Interior fill color (bars, boxes)      | Common in `geom_bar`, `geom_boxplot`      |\n",
    "| `shape`       | Point symbol shape                     | Used in scatterplots                       |\n",
    "| `size`        | Point or line size                     | Good for magnitude comparisons             |\n",
    "| `alpha`       | Transparency                           | Ranges from 0 (invisible) to 1 (opaque)    |\n",
    "| `group`       | Used to group lines                    | Important in time-series                  |\n",
    "\n",
    "```r\n",
    "ggplot(data, aes(x = year, y = pop, color = continent)) +\n",
    "  geom_line()\n",
    "```\n",
    "* `fill` : what is the purpose of fill when creating a box plot, to include an additional visual dimension by color\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Geometric Objects (`geom_*()`)\n",
    "### What is a Geom?\n",
    "A **geom** specifies the type of plot (scatter, bar, line, etc.).\n",
    "\n",
    "### üß± Common Geoms and Use Cases\n",
    "| Geom Function       | Type                 | Example Usage                             |\n",
    "|---------------------|----------------------|-------------------------------------------|\n",
    "| `geom_point()`      | Scatterplot          | Compare two continuous variables          |\n",
    "| `geom_bar()`        | Bar (count)          | Category frequency                        |\n",
    "| `geom_col()`        | Bar (pre-aggregated) | Plot actual values instead of counts      |\n",
    "| `geom_histogram()`  | Histogram            | Distribution of continuous variable       |\n",
    "| `geom_boxplot()`    | Boxplot              | Summarize numeric data across categories  |\n",
    "| `geom_line()`       | Line plot            | Time series or continuous trend           |\n",
    "| `geom_smooth()`     | Trend line           | Add LOESS or linear model fit             |\n",
    "| `geom_density()`    | Density estimate     | Smooth distribution shape                 |\n",
    "| `geom_violin()`     | Violin plot          | Boxplot + density                         |\n",
    "| `geom_text()`       | Text annotations     | To label points in a plot                 |\n",
    "| `geom_tile()`       | heatmap              | Visualizing the relationship between 2 categorical                 |\n",
    "| `geom_jitter()`       | overlay your data on a boxplot     |                           |\n",
    "\n",
    "```r\n",
    "ggplot(mpg, aes(x = class)) +\n",
    "  geom_bar(fill = \"steelblue\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìê Coordinate Systems\n",
    "### Why Modify Coordinates?\n",
    "To improve readability or support different visualization formats.\n",
    "\n",
    "| Function           | Description                                |\n",
    "|--------------------|--------------------------------------------|\n",
    "| `coord_flip()`      | Switch x and y axes                        |\n",
    "| `coord_polar()`     | Create pie chart or radial visualizations  |\n",
    "| `xlim()` / `ylim()` | Manually set axis limits                  |\n",
    "\n",
    "```r\n",
    "ggplot(mpg, aes(x = class)) +\n",
    "  geom_bar() +\n",
    "  coord_flip()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Faceting for Small Multiples\n",
    "Faceting allows data to be split across multiple panels.\n",
    "\n",
    "| Function               | Use Case                              |\n",
    "|------------------------|----------------------------------------|\n",
    "| `facet_wrap(~ var)`    | Create multiple plots by one variable |\n",
    "| `facet_grid(row ~ col)`| Grid layout for two variables         |\n",
    "\n",
    "```r\n",
    "ggplot(gapminder, aes(x = year, y = life_expectancy)) +\n",
    "  geom_line() +\n",
    "  facet_wrap(~ continent)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üè∑Ô∏è Labels and Titles\n",
    "Make your plots self-explanatory.\n",
    "\n",
    "```r\n",
    "labs(\n",
    "  title = \"Life Expectancy Over Time\",\n",
    "  subtitle = \"Across Continents\",\n",
    "  x = \"Year\",\n",
    "  y = \"Life Expectancy\",\n",
    "  caption = \"Source: Gapminder\"\n",
    ")\n",
    "```\n",
    "Use `geom_text()` to add annotations at specific points.\n",
    "\n",
    "---\n",
    "\n",
    "## üé® Themes and Visual Appearance\n",
    "Themes control the non-data aspects of your plot (text, background, margins).\n",
    "\n",
    "| Theme Function     | Description                               |\n",
    "|--------------------|-------------------------------------------|\n",
    "| `theme_minimal()`  | Clean with minimal distractions           |\n",
    "| `theme_classic()`  | Traditional axis lines                    |\n",
    "| `theme_light()`    | Light grid background                     |\n",
    "| `theme_void()`     | Blank plot for maps or infographics       |\n",
    "| `theme()`          | Customize individual elements manually    |\n",
    "\n",
    "```r\n",
    "ggplot(...) + theme_minimal()\n",
    "```\n",
    "\n",
    "### Customizing with `theme()`\n",
    "```r\n",
    "+ theme(\n",
    "    axis.text.x = element_text(angle = 45),\n",
    "    legend.position = \"bottom\"\n",
    "  )\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üåà Color Scales and Palettes\n",
    "### Managing Color\n",
    "```r\n",
    "scale_fill_brewer(palette = \"Set2\")\n",
    "scale_color_manual(values = c(\"red\", \"blue\"))\n",
    "```\n",
    "\n",
    "| Function                | Purpose                                  |\n",
    "|-------------------------|------------------------------------------|\n",
    "| `scale_fill_brewer()`   | Fill colors using RColorBrewer palettes  |\n",
    "| `scale_color_manual()`  | Manually define line/point colors        |\n",
    "| `scale_fill_gradient()` | Continuous color gradient fill           |\n",
    "\n",
    "> ‚úÖ Tip: Avoid red-green palettes for accessibility.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Best Practices in Plot Design\n",
    "### DO:\n",
    "- Use **bar charts** instead of **pie charts**\n",
    "- Start **axes at 0** (unless justified)\n",
    "- Add **meaningful titles and labels**\n",
    "- Apply **color sparingly and meaningfully**\n",
    "- Organize bars by **logical order**\n",
    "- Use **facet wrapping** for category comparisons\n",
    "\n",
    "### AVOID:\n",
    "- Overuse of colors or decorations\n",
    "- Omitting legends or labels\n",
    "- Skewed axes or cherry-picked scales\n",
    "- Using 3D or distorted perspectives\n",
    "\n",
    "---\n",
    "\n",
    "## üîé Example: Clean and Informative Plot\n",
    "```r\n",
    "ggplot(gapminder, aes(x = continent, fill = continent)) +\n",
    "  geom_bar() +\n",
    "  labs(\n",
    "    title = \"Number of Countries by Continent\",\n",
    "    x = \"Continent\",\n",
    "    y = \"Number of Countries\"\n",
    "  ) +\n",
    "  scale_fill_brewer(palette = \"Pastel1\") +\n",
    "  theme_minimal()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2318a34a",
   "metadata": {},
   "source": [
    "# L22, L23, L24 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c1a5ce",
   "metadata": {},
   "source": [
    "# üß† Lecture Concepts Review (Expanded) ‚Äî Part 1: Simulation-Based Inference (Bootstrapping)\n",
    "\n",
    "This document offers an in-depth, conceptually rich breakdown of **Lecture 22**: Simulation-Based Inference and Bootstrapping.\n",
    "\n",
    "---\n",
    "\n",
    "## üìò Lecture 22: Simulation-Based Inference ‚Äì Bootstrapping\n",
    "\n",
    "### üß≠ Context & Motivation\n",
    "In previous lectures, we've learned how to:\n",
    "- Import data (CSV, JSON, web scraping)\n",
    "- Clean and wrangle data (subsetting, merging, functions)\n",
    "- Summarize data (mean, median, variance)\n",
    "- Visualize relationships using `ggplot2`\n",
    "\n",
    "This provided the groundwork for **basic data analysis**, but all of that was descriptive ‚Äî based on **samples**. To go from sample to population, we need a new tool: **statistical inference**.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† What is Statistical Inference?\n",
    "**Statistical inference** refers to drawing conclusions about a population based on a sample. It lets us:\n",
    "- Estimate unknown population values (like the population mean \\( \\mu \\))\n",
    "- Assess uncertainty in our estimates\n",
    "\n",
    "It‚Äôs based on the idea that any single sample is just one of many that could have been drawn.\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Why Do We Sample?\n",
    "Often, we cannot collect data on the full population due to constraints:\n",
    "- Cost (e.g., testing all smokers with CT scans)\n",
    "- Time (e.g., surveying all undergrad students)\n",
    "- Accessibility (e.g., testing everyone in a country)\n",
    "\n",
    "So we **randomly sample** and use the sample to infer characteristics of the population.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Sampling Variability\n",
    "- Different random samples yield different estimates\n",
    "- This variability is called **sampling variability**\n",
    "- It's the foundation of **inference**, because it defines how uncertain our sample estimates are\n",
    "\n",
    "Example: Two samples of size 50 can yield very different sample means due to random chance\n",
    "\n",
    "---\n",
    "\n",
    "### üìà Sampling Distribution\n",
    "- The **sampling distribution** of a statistic (like the mean) is the distribution of that statistic across many repeated samples\n",
    "- We rarely get to see this distribution in practice\n",
    "\n",
    "But we can **simulate** it using bootstrapping.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ Bootstrapping: A Resampling Technique\n",
    "\n",
    "**Definition:** Bootstrapping simulates the sampling distribution of a statistic by repeatedly resampling (with replacement) from your observed sample.\n",
    "\n",
    "#### Why Bootstrap?\n",
    "- Does not assume normality or other parametric forms\n",
    "- Enables inference from *one* sample by mimicking sampling variability\n",
    "\n",
    "#### Procedure:\n",
    "1. Start with a sample (size \\( n \\))\n",
    "2. Draw a new sample of size \\( n \\) **with replacement** from that sample\n",
    "3. Compute a statistic (e.g., mean) from this bootstrap sample\n",
    "4. Repeat 1000‚Äì2000 times to get a **bootstrap distribution**\n",
    "\n",
    "---\n",
    "\n",
    "### üßÆ Example in R\n",
    "```r\n",
    "# Initial sample\n",
    "sample_data <- sample(population_data, size = 50, replace = FALSE)\n",
    "\n",
    "# Bootstrap loop\n",
    "boot_means <- numeric(1000)\n",
    "for (i in 1:1000) {\n",
    "  boot_sample <- sample(sample_data, size = 50, replace = TRUE)\n",
    "  boot_means[i] <- mean(boot_sample)\n",
    "}\n",
    "\n",
    "# Plot bootstrap distribution\n",
    "hist(boot_means, breaks = 30)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîê Confidence Intervals (CI)\n",
    "A **95% Confidence Interval** captures the population value with 95% probability, *if* we could resample repeatedly.\n",
    "\n",
    "#### Percentile Method (Simulation-based):\n",
    "- Sort the bootstrap statistics\n",
    "- Take the 2.5th and 97.5th percentiles\n",
    "```r\n",
    "quantile(boot_means, c(0.025, 0.975))\n",
    "```\n",
    "\n",
    "#### Interpretation:\n",
    "> ‚ÄúWe are 95% confident that the true population mean is between X and Y.‚Äù\n",
    "\n",
    "This is based on the fact that the center of the bootstrap distribution approximates the true population parameter.\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Statistical Inference via CI\n",
    "CIs help us:\n",
    "- Estimate population values\n",
    "- Perform **hypothesis testing**\n",
    "\n",
    "#### Decision Rules:\n",
    "- If a reference value (like 60) is **outside** the CI: the true mean is **significantly different** from 60\n",
    "- If a value is **inside** the CI: we **cannot** say it's significantly different\n",
    "\n",
    "#### Example:\n",
    "> If CI = [63, 72], then:\n",
    "> - 60 is significantly lower ‚Üí mean is greater than 60\n",
    "> - 73 is significantly higher ‚Üí mean is less than 73\n",
    "> - 65 is not significantly different\n",
    "\n",
    "This leads into **hypothesis testing**, which connects to later lectures.\n",
    "\n",
    "---\n",
    "\n",
    "### ü™Ñ Summary of Lecture 22 Concepts\n",
    "| Concept                   | Definition/Explanation                                                                 |\n",
    "|--------------------------|----------------------------------------------------------------------------------------|\n",
    "| Statistical inference    | Inferring population characteristics from a sample                                     |\n",
    "| Sampling variability     | The fact that each random sample gives different results                               |\n",
    "| Sampling distribution    | Distribution of a statistic across many random samples                                |\n",
    "| Bootstrap sample         | A sample of size \\( n \\) drawn **with replacement** from the original sample           |\n",
    "| Bootstrap distribution   | Distribution of statistics (means, medians, etc.) from many bootstrap samples         |\n",
    "| Confidence Interval (CI) | Range of plausible values for the population parameter                                |\n",
    "| Percentile CI            | CI based on 2.5% and 97.5% quantiles of the bootstrap distribution                     |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04288ca1",
   "metadata": {},
   "source": [
    "# üß† Lecture Concepts Review (Expanded) ‚Äî Part 2: Simple Linear Regression (SLR)\n",
    "\n",
    "This section offers a detailed, structured breakdown of **Lecture 23**, which covers Simple Linear Regression using numeric variables.\n",
    "\n",
    "---\n",
    "\n",
    "## üìò Lecture 23: Simple Linear Regression with Numeric Predictors\n",
    "\n",
    "### üß≠ Context & Motivation\n",
    "So far, we‚Äôve explored descriptive statistics and inference (e.g., bootstrapping) mostly around **summary metrics** like means. Now we turn to **modeling relationships** ‚Äî specifically between two numeric variables ‚Äî using **regression**.\n",
    "\n",
    "Use case example: At Amazon, should you schedule more oil changes to reduce truck repair costs? To answer this, you can model the relationship between number of oil changes and cost of repairs.\n",
    "\n",
    "---\n",
    "\n",
    "### üìê What is Simple Linear Regression?\n",
    "**Simple Linear Regression (SLR)** models the relationship between a **predictor** (independent variable) \\( x \\) and a **response** (dependent variable) \\( y \\) using a straight line:\n",
    "\n",
    "\\[ y = mx + b + \\varepsilon \\]\n",
    "\n",
    "Where:\n",
    "- \\( m \\) is the **slope** (rate of change)\n",
    "- \\( b \\) is the **intercept** (value of \\( y \\) when \\( x = 0 \\))\n",
    "- \\( \\varepsilon \\) is the **error term** (random noise)\n",
    "\n",
    "---\n",
    "\n",
    "### üîé Visualizing the Relationship\n",
    "Before modeling, always **visualize** your data with a **scatterplot** to assess:\n",
    "- Is the relationship linear?\n",
    "- Is there a clear trend (positive/negative)?\n",
    "\n",
    "Example: More oil changes ‚Üí lower repair costs ‚Üí negative linear trend\n",
    "\n",
    "---\n",
    "\n",
    "### üìè Slope & Intercept Interpretation\n",
    "Suppose our regression model is:\n",
    "\n",
    "\\[ \\text{repair} = -72 \\times \\text{oil changes} + 652 \\]\n",
    "\n",
    "Then:\n",
    "- **Slope**: For each additional oil change, **repair cost decreases by $72**\n",
    "- **Intercept**: If no oil changes are done, the **average repair cost is $652**\n",
    "\n",
    "Note: The intercept is often outside the range of meaningful values (e.g., 0 oil changes might not be realistic).\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Fitting a Linear Model in R\n",
    "```r\n",
    "fit <- lm(repair ~ oilchanges, data = dataset)\n",
    "coef(fit)  # Returns intercept and slope\n",
    "```\n",
    "\n",
    "To extract them individually:\n",
    "```r\n",
    "intercept <- coef(fit)[1]\n",
    "slope <- coef(fit)[2]\n",
    "```\n",
    "\n",
    "To visualize the regression line:\n",
    "```r\n",
    "plot(dataset$oilchanges, dataset$repair)\n",
    "abline(fit, col = \"red\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Sampling Variability in Regression\n",
    "Just like the **sample mean**, slope and intercept estimates **vary from sample to sample**:\n",
    "- This variability makes inference necessary\n",
    "- Bootstrapping can help us **estimate confidence intervals** for the slope/intercept\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ Bootstrap for Regression Coefficients\n",
    "We can apply bootstrapping to linear regression parameters:\n",
    "\n",
    "#### Procedure:\n",
    "1. Sample \\( n \\) rows from the dataset **with replacement**\n",
    "2. Fit a linear model to the bootstrap sample\n",
    "3. Extract and store the **slope** and **intercept**\n",
    "4. Repeat 1000+ times\n",
    "5. Analyze the distribution of estimates\n",
    "\n",
    "#### R Example:\n",
    "```r\n",
    "boot_slopes <- numeric(1000)\n",
    "boot_intercepts <- numeric(1000)\n",
    "n <- nrow(data)\n",
    "\n",
    "for (i in 1:1000) {\n",
    "  boot_indices <- sample(1:n, size = n, replace = TRUE)\n",
    "  boot_sample <- data[boot_indices, ]\n",
    "  model <- lm(repair ~ oilchanges, data = boot_sample)\n",
    "  coefs <- coef(model)\n",
    "  boot_intercepts[i] <- coefs[1]\n",
    "  boot_slopes[i] <- coefs[2]\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîê Bootstrap Confidence Intervals for Coefficients\n",
    "Use the percentile method:\n",
    "```r\n",
    "quantile(boot_slopes, c(0.025, 0.975))  # CI for slope\n",
    "quantile(boot_intercepts, c(0.025, 0.975))  # CI for intercept\n",
    "```\n",
    "\n",
    "### üß† Interpretation:\n",
    "If the 95% CI for slope **does not contain 0**, the slope is **significantly different from zero** ‚Üí there is a significant relationship between variables.\n",
    "\n",
    "If the CI **contains 0** ‚Üí **no significant relationship**.\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Summary of Lecture 23 Concepts\n",
    "| Concept                         | Definition/Explanation                                                                 |\n",
    "|--------------------------------|----------------------------------------------------------------------------------------|\n",
    "| Simple Linear Regression (SLR) | A model relating two numeric variables with a straight line                           |\n",
    "| Slope (\\( m \\))                | Average change in \\( y \\) for a 1-unit change in \\( x \\)                               |\n",
    "| Intercept (\\( b \\))            | Predicted \\( y \\) when \\( x = 0 \\)                                                   |\n",
    "| Error term (\\( \\varepsilon \\)) | Captures deviation from the line due to random noise                                  |\n",
    "| lm()                           | R function for fitting linear models                                                  |\n",
    "| coef()                         | Extracts slope and intercept from fitted model                                        |\n",
    "| abline()                       | Adds regression line to scatterplot                                                   |\n",
    "| Bootstrap regression           | Repeatedly resampling rows to estimate slope/intercept variability                    |\n",
    "| Confidence interval (CI)       | Range of likely values for true slope/intercept based on resampled estimates          |\n",
    "\n",
    "Let me know when you're ready for **Part 3: k-Nearest Neighbors**!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb8dac5",
   "metadata": {},
   "source": [
    "# üß† Lecture Concepts Review (Expanded) ‚Äî Part 3: k-Nearest Neighbors (k-NN)\n",
    "\n",
    "This section offers a detailed and structured breakdown of **Lecture 24**, which introduces the supervised learning algorithm **k-Nearest Neighbors (k-NN)**.\n",
    "\n",
    "---\n",
    "\n",
    "## üìò Lecture 24: Prediction with k-Nearest Neighbors (k-NN)\n",
    "\n",
    "### üß≠ Context & Motivation\n",
    "We‚Äôve now seen descriptive statistics, bootstrapping, and modeling numeric relationships (SLR). But what if our **goal is to make predictions** ‚Äî especially for new, unseen data?\n",
    "\n",
    "That‚Äôs where **machine learning** comes in.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† What is Prediction in ML?\n",
    "Prediction is about using known **features** (inputs) to forecast or classify unknown **outcomes** (outputs):\n",
    "\n",
    "| Task         | Type of Output | ML Type       |\n",
    "|--------------|----------------|----------------|\n",
    "| Predict tumor type (benign/malignant) | Categorical     | Classification |\n",
    "| Predict surf height                  | Numeric         | Regression      |\n",
    "\n",
    "---\n",
    "\n",
    "### ü§ñ Supervised Learning\n",
    "**Supervised Learning**: Learn a model from data where both inputs (X) and outputs (Y) are known.\n",
    "\n",
    "- Inputs = **Features** (a.k.a. predictors, covariates)\n",
    "- Output = **Target** (a.k.a. label, response)\n",
    "\n",
    "---\n",
    "\n",
    "### üîç k-Nearest Neighbors (k-NN) Algorithm\n",
    "**k-NN** is a simple supervised learning algorithm used for both **classification** and **regression**.\n",
    "\n",
    "#### üîß How it Works:\n",
    "1. Choose a value of **k** (e.g. 3)\n",
    "2. For a new observation, compute its **distance** to all training observations\n",
    "3. Identify the **k closest (nearest) neighbors**\n",
    "4. Predict the outcome:\n",
    "   - **Classification**: Use majority vote\n",
    "   - **Regression**: Use average of neighbors' values\n",
    "\n",
    "---\n",
    "\n",
    "### üå∏ Visual Example: Classifying Flower Species\n",
    "- Dataset: Iris (sepal width and sepal length)\n",
    "- Task: Predict the species of a new flower\n",
    "\n",
    "Steps:\n",
    "- For a new flower (the ‚Äústar‚Äù point), calculate distances to all others\n",
    "- Choose the k-nearest labeled flowers\n",
    "- Classify the new flower as the **most common label among neighbors**\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Selecting k: Accuracy & Testing\n",
    "Predictions can change based on the value of **k**.\n",
    "\n",
    "#### To choose k:\n",
    "- Split data into **training** and **testing** sets\n",
    "- Try different values of **k**\n",
    "- Pick the one with the **highest accuracy on the test set**\n",
    "\n",
    "This is the concept of a **training/testing split**:\n",
    "- Training data is used to train the model\n",
    "- Testing data is used to evaluate prediction performance\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Accuracy & Confusion Matrix\n",
    "To assess how well k-NN performs:\n",
    "\n",
    "- **Accuracy** = Proportion of correct classifications\n",
    "- **Confusion Matrix** = Table comparing predictions to actual labels\n",
    "  - Diagonal = correct predictions\n",
    "  - Off-diagonal = misclassifications\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Implementing k-NN in R\n",
    "Load packages:\n",
    "```r\n",
    "library(class)      # for knn()\n",
    "library(ggplot2)    # for visualization\n",
    "```\n",
    "\n",
    "Split data:\n",
    "```r\n",
    "n <- nrow(iris)\n",
    "train_index <- sample(1:n, size = 0.7 * n)\n",
    "train_x <- iris[train_index, c(\"Sepal.Length\", \"Sepal.Width\")]\n",
    "train_y <- iris[train_index, \"Species\"]\n",
    "test_x <- iris[-train_index, c(\"Sepal.Length\", \"Sepal.Width\")]\n",
    "test_y <- iris[-train_index, \"Species\"]\n",
    "```\n",
    "\n",
    "Run k-NN with different values of k:\n",
    "```r\n",
    "library(class)\n",
    "predictions <- knn(train = train_x, test = test_x, cl = train_y, k = 5)\n",
    "```\n",
    "\n",
    "Compute accuracy:\n",
    "```r\n",
    "mean(predictions == test_y)\n",
    "```\n",
    "\n",
    "Create confusion matrix:\n",
    "```r\n",
    "table(Predicted = predictions, Actual = test_y)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üåÄ Visualization & Model Insights\n",
    "- Scatterplots can help assess how well separation occurs between classes\n",
    "- Using additional features (e.g., petal length) can **improve accuracy**\n",
    "- Larger values of k **smooth out** predictions but may **miss boundaries**\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Summary of Lecture 24 Concepts\n",
    "| Concept              | Definition/Explanation                                                      |\n",
    "|----------------------|-------------------------------------------------------------------------------|\n",
    "| Prediction           | Forecasting unknown outcomes using known inputs                              |\n",
    "| Classification       | Predicting **categorical** outcomes                                           |\n",
    "| Regression           | Predicting **numeric** outcomes                                               |\n",
    "| Supervised Learning  | Model learns from labeled data (features + output)                            |\n",
    "| Feature              | Input variable (a.k.a. predictor, covariate)                                  |\n",
    "| Label/Target         | Output variable (a.k.a. response, class)                                      |\n",
    "| k-NN Algorithm       | Predict outcome using the majority or average of the k closest neighbors      |\n",
    "| Distance Metric      | Usually Euclidean distance between feature vectors                            |\n",
    "| Training/Test Split  | Training = learn model, Testing = evaluate model performance                  |\n",
    "| Accuracy             | % of correct predictions on test data                                         |\n",
    "| Confusion Matrix     | Table summarizing correct and incorrect classifications                       |\n",
    "\n",
    "Let me know if you'd like to compile all three lectures into one full printable study guide PDF or expand into lab questions! üöÄ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3badcbf9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
